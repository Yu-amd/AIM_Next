{
  "model_id": "meta-llama/Llama-3.2-11B-Instruct",
  "variant_id": "meta-llama/Llama-3.2-11B-Instruct-fp16",
  "version": "1.0.0-fp16",
  "parameters": "11B",
  "precision": "fp16",
  "memory_requirement_gb": 26.0,
  "recommended_partition_gb": 32.5,
  "gpu_sharing": {
    "enabled": true,
    "memory_limit_gb": 32.5,
    "partition_id": null,
    "qos_priority": "medium",
    "compute_mode": "SPX",
    "memory_mode": "NPS1",
    "partition_count": 1,
    "partition_size_gb": 192.0
  },
  "resource_requirements": {
    "gpu_memory_gb": 26.0,
    "gpu_count": 1,
    "cpu_cores": 2,
    "system_memory_gb": 16
  },
  "metadata": {
    "quantization": "fp16",
    "base_model": "meta-llama/Llama-3.2-11B-Instruct",
    "parameters": "11B",
    "partition_config": {
      "compute_mode": "SPX",
      "memory_mode": "NPS1",
      "partition_count": 1,
      "partition_size_gb": 192.0
    }
  }
}