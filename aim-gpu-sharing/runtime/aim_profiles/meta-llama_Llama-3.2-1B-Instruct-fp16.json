{
  "model_id": "meta-llama/Llama-3.2-1B-Instruct",
  "variant_id": "meta-llama/Llama-3.2-1B-Instruct-fp16",
  "version": "1.0.0-fp16",
  "parameters": "1B",
  "precision": "fp16",
  "memory_requirement_gb": 5.0,
  "recommended_partition_gb": 6.25,
  "gpu_sharing": {
    "enabled": true,
    "memory_limit_gb": 6.25,
    "partition_id": null,
    "qos_priority": "medium"
  },
  "resource_requirements": {
    "gpu_memory_gb": 5.0,
    "gpu_count": 1,
    "cpu_cores": 2,
    "system_memory_gb": 16
  },
  "metadata": {
    "quantization": "fp16",
    "base_model": "meta-llama/Llama-3.2-1B-Instruct",
    "parameters": "1B"
  }
}