{
  "model_id": "google/gemma-3-12B",
  "variant_id": "google/gemma-3-12B-fp16",
  "version": "1.0.0-fp16",
  "parameters": "12B",
  "precision": "fp16",
  "memory_requirement_gb": 28.0,
  "recommended_partition_gb": 35.0,
  "gpu_sharing": {
    "enabled": true,
    "memory_limit_gb": 35.0,
    "partition_id": null,
    "qos_priority": "medium"
  },
  "resource_requirements": {
    "gpu_memory_gb": 28.0,
    "gpu_count": 1,
    "cpu_cores": 2,
    "system_memory_gb": 16
  },
  "metadata": {
    "quantization": "fp16",
    "base_model": "google/gemma-3-12B",
    "parameters": "12B"
  }
}